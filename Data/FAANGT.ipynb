{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAANGT Notebook\n",
    "This notebook is a rough draft to design and test FAANGT.py module functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Timeseries function from alpha_vantage SDK\n",
    "import pandas as pd\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key is available\n"
     ]
    }
   ],
   "source": [
    "# Load in API key\n",
    "load_dotenv()\n",
    "alpha_vantage_key = os.getenv('ALPHAVANTAGE_API_KEY')\n",
    "\n",
    "# Confirm the availability of your Mapbox API access token by checking its type\n",
    "if type(alpha_vantage_key) == type(''):\n",
    "    print('Key is available')\n",
    "else: \n",
    "    print('Try again')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeries(key = alpha_vantage_key, output_format='pandas') #Note 500 requests per day cap, 5 per min\n",
    "FAANGT_list=['FB','AAPL','AMZN','NFLX', 'GOOG', 'TSLA']\n",
    "FAANGT_df_list = [] #iniate df list for later concatenation\n",
    "FAANGT_close_df_list = [] #iniate df list for just close prices later concatenation\n",
    "for ticker in FAANGT_list:\n",
    "    ticker_data, meta_data = ts.get_daily(symbol=ticker, outputsize='full') #using Alpha Vantage API to grab S&P 500 ETF (ticker symbol = SPY), gives 20+ years of price data\n",
    "    ticker_data.columns = [ticker + ' open', ticker + ' high', ticker + ' low', ticker + ' close', ticker + ' volume'] #rename columns automatically\n",
    "    FAANGT_df_list.append(ticker_data) #add dataframe to the list\n",
    "    FAANGT_close_df_list.append(ticker_data[ticker + ' close']) # Just the 'close' column\n",
    "    time.sleep(25) #Note 500 requests per day cap, 5 per min\n",
    "\n",
    "FAANGT_df = pd.concat(FAANGT_df_list, axis=1, join='outer')\n",
    "FAANGT_close_df = pd.concat(FAANGT_close_df_list, axis=1, join='outer')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FB open</th>\n",
       "      <th>FB high</th>\n",
       "      <th>FB low</th>\n",
       "      <th>FB close</th>\n",
       "      <th>FB volume</th>\n",
       "      <th>AAPL open</th>\n",
       "      <th>AAPL high</th>\n",
       "      <th>AAPL low</th>\n",
       "      <th>AAPL close</th>\n",
       "      <th>AAPL volume</th>\n",
       "      <th>...</th>\n",
       "      <th>GOOG open</th>\n",
       "      <th>GOOG high</th>\n",
       "      <th>GOOG low</th>\n",
       "      <th>GOOG close</th>\n",
       "      <th>GOOG volume</th>\n",
       "      <th>TSLA open</th>\n",
       "      <th>TSLA high</th>\n",
       "      <th>TSLA low</th>\n",
       "      <th>TSLA close</th>\n",
       "      <th>TSLA volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.69</td>\n",
       "      <td>77.37</td>\n",
       "      <td>77.62</td>\n",
       "      <td>2487300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.00</td>\n",
       "      <td>81.69</td>\n",
       "      <td>77.31</td>\n",
       "      <td>80.25</td>\n",
       "      <td>3564600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.62</td>\n",
       "      <td>83.25</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.50</td>\n",
       "      <td>2932700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.06</td>\n",
       "      <td>85.37</td>\n",
       "      <td>80.62</td>\n",
       "      <td>83.62</td>\n",
       "      <td>3384700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.62</td>\n",
       "      <td>88.37</td>\n",
       "      <td>84.00</td>\n",
       "      <td>88.31</td>\n",
       "      <td>3721500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-11</th>\n",
       "      <td>300.7500</td>\n",
       "      <td>306.84</td>\n",
       "      <td>299.6900</td>\n",
       "      <td>306.53</td>\n",
       "      <td>18920086.0</td>\n",
       "      <td>123.50</td>\n",
       "      <td>126.27</td>\n",
       "      <td>122.77</td>\n",
       "      <td>125.91</td>\n",
       "      <td>126142826.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2291.86</td>\n",
       "      <td>2322.0000</td>\n",
       "      <td>2283.00</td>\n",
       "      <td>2308.76</td>\n",
       "      <td>1605548.0</td>\n",
       "      <td>599.2400</td>\n",
       "      <td>627.0999</td>\n",
       "      <td>595.600</td>\n",
       "      <td>617.20</td>\n",
       "      <td>46503896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12</th>\n",
       "      <td>301.1300</td>\n",
       "      <td>304.96</td>\n",
       "      <td>298.1900</td>\n",
       "      <td>302.55</td>\n",
       "      <td>24641010.0</td>\n",
       "      <td>123.40</td>\n",
       "      <td>124.64</td>\n",
       "      <td>122.25</td>\n",
       "      <td>122.77</td>\n",
       "      <td>112172282.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2261.71</td>\n",
       "      <td>2285.3700</td>\n",
       "      <td>2230.05</td>\n",
       "      <td>2239.08</td>\n",
       "      <td>1746664.0</td>\n",
       "      <td>602.4900</td>\n",
       "      <td>620.4100</td>\n",
       "      <td>586.765</td>\n",
       "      <td>589.89</td>\n",
       "      <td>33823646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-13</th>\n",
       "      <td>306.0833</td>\n",
       "      <td>308.86</td>\n",
       "      <td>302.7701</td>\n",
       "      <td>305.26</td>\n",
       "      <td>18079160.0</td>\n",
       "      <td>124.58</td>\n",
       "      <td>126.15</td>\n",
       "      <td>124.26</td>\n",
       "      <td>124.97</td>\n",
       "      <td>105861339.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2261.09</td>\n",
       "      <td>2276.6012</td>\n",
       "      <td>2242.72</td>\n",
       "      <td>2261.97</td>\n",
       "      <td>1333508.0</td>\n",
       "      <td>601.5450</td>\n",
       "      <td>606.4599</td>\n",
       "      <td>559.650</td>\n",
       "      <td>571.69</td>\n",
       "      <td>44184916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>309.5400</td>\n",
       "      <td>316.85</td>\n",
       "      <td>309.0800</td>\n",
       "      <td>315.94</td>\n",
       "      <td>19245724.0</td>\n",
       "      <td>126.25</td>\n",
       "      <td>127.89</td>\n",
       "      <td>125.85</td>\n",
       "      <td>127.45</td>\n",
       "      <td>81917951.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2291.83</td>\n",
       "      <td>2321.1400</td>\n",
       "      <td>2283.32</td>\n",
       "      <td>2316.16</td>\n",
       "      <td>1331248.0</td>\n",
       "      <td>583.4100</td>\n",
       "      <td>592.8700</td>\n",
       "      <td>570.460</td>\n",
       "      <td>589.74</td>\n",
       "      <td>33370856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-17</th>\n",
       "      <td>313.5500</td>\n",
       "      <td>315.68</td>\n",
       "      <td>311.5800</td>\n",
       "      <td>315.46</td>\n",
       "      <td>15356141.0</td>\n",
       "      <td>126.82</td>\n",
       "      <td>126.93</td>\n",
       "      <td>125.17</td>\n",
       "      <td>126.27</td>\n",
       "      <td>73810407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2309.32</td>\n",
       "      <td>2323.3400</td>\n",
       "      <td>2295.00</td>\n",
       "      <td>2321.41</td>\n",
       "      <td>991229.0</td>\n",
       "      <td>575.5531</td>\n",
       "      <td>589.7300</td>\n",
       "      <td>561.200</td>\n",
       "      <td>576.83</td>\n",
       "      <td>32118062.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5420 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FB open  FB high    FB low  FB close   FB volume  AAPL open  \\\n",
       "date                                                                       \n",
       "1999-11-01       NaN      NaN       NaN       NaN         NaN      80.00   \n",
       "1999-11-02       NaN      NaN       NaN       NaN         NaN      78.00   \n",
       "1999-11-03       NaN      NaN       NaN       NaN         NaN      81.62   \n",
       "1999-11-04       NaN      NaN       NaN       NaN         NaN      82.06   \n",
       "1999-11-05       NaN      NaN       NaN       NaN         NaN      84.62   \n",
       "...              ...      ...       ...       ...         ...        ...   \n",
       "2021-05-11  300.7500   306.84  299.6900    306.53  18920086.0     123.50   \n",
       "2021-05-12  301.1300   304.96  298.1900    302.55  24641010.0     123.40   \n",
       "2021-05-13  306.0833   308.86  302.7701    305.26  18079160.0     124.58   \n",
       "2021-05-14  309.5400   316.85  309.0800    315.94  19245724.0     126.25   \n",
       "2021-05-17  313.5500   315.68  311.5800    315.46  15356141.0     126.82   \n",
       "\n",
       "            AAPL high  AAPL low  AAPL close  AAPL volume  ...  GOOG open  \\\n",
       "date                                                      ...              \n",
       "1999-11-01      80.69     77.37       77.62    2487300.0  ...        NaN   \n",
       "1999-11-02      81.69     77.31       80.25    3564600.0  ...        NaN   \n",
       "1999-11-03      83.25     81.00       81.50    2932700.0  ...        NaN   \n",
       "1999-11-04      85.37     80.62       83.62    3384700.0  ...        NaN   \n",
       "1999-11-05      88.37     84.00       88.31    3721500.0  ...        NaN   \n",
       "...               ...       ...         ...          ...  ...        ...   \n",
       "2021-05-11     126.27    122.77      125.91  126142826.0  ...    2291.86   \n",
       "2021-05-12     124.64    122.25      122.77  112172282.0  ...    2261.71   \n",
       "2021-05-13     126.15    124.26      124.97  105861339.0  ...    2261.09   \n",
       "2021-05-14     127.89    125.85      127.45   81917951.0  ...    2291.83   \n",
       "2021-05-17     126.93    125.17      126.27   73810407.0  ...    2309.32   \n",
       "\n",
       "            GOOG high  GOOG low  GOOG close  GOOG volume  TSLA open  \\\n",
       "date                                                                  \n",
       "1999-11-01        NaN       NaN         NaN          NaN        NaN   \n",
       "1999-11-02        NaN       NaN         NaN          NaN        NaN   \n",
       "1999-11-03        NaN       NaN         NaN          NaN        NaN   \n",
       "1999-11-04        NaN       NaN         NaN          NaN        NaN   \n",
       "1999-11-05        NaN       NaN         NaN          NaN        NaN   \n",
       "...               ...       ...         ...          ...        ...   \n",
       "2021-05-11  2322.0000   2283.00     2308.76    1605548.0   599.2400   \n",
       "2021-05-12  2285.3700   2230.05     2239.08    1746664.0   602.4900   \n",
       "2021-05-13  2276.6012   2242.72     2261.97    1333508.0   601.5450   \n",
       "2021-05-14  2321.1400   2283.32     2316.16    1331248.0   583.4100   \n",
       "2021-05-17  2323.3400   2295.00     2321.41     991229.0   575.5531   \n",
       "\n",
       "            TSLA high  TSLA low  TSLA close  TSLA volume  \n",
       "date                                                      \n",
       "1999-11-01        NaN       NaN         NaN          NaN  \n",
       "1999-11-02        NaN       NaN         NaN          NaN  \n",
       "1999-11-03        NaN       NaN         NaN          NaN  \n",
       "1999-11-04        NaN       NaN         NaN          NaN  \n",
       "1999-11-05        NaN       NaN         NaN          NaN  \n",
       "...               ...       ...         ...          ...  \n",
       "2021-05-11   627.0999   595.600      617.20   46503896.0  \n",
       "2021-05-12   620.4100   586.765      589.89   33823646.0  \n",
       "2021-05-13   606.4599   559.650      571.69   44184916.0  \n",
       "2021-05-14   592.8700   570.460      589.74   33370856.0  \n",
       "2021-05-17   589.7300   561.200      576.83   32118062.0  \n",
       "\n",
       "[5420 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "FAANGT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FB close</th>\n",
       "      <th>AAPL close</th>\n",
       "      <th>AMZN close</th>\n",
       "      <th>NFLX close</th>\n",
       "      <th>GOOG close</th>\n",
       "      <th>TSLA close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>77.62</td>\n",
       "      <td>69.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.25</td>\n",
       "      <td>66.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>81.50</td>\n",
       "      <td>65.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>83.62</td>\n",
       "      <td>63.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>88.31</td>\n",
       "      <td>64.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-11</th>\n",
       "      <td>306.53</td>\n",
       "      <td>125.91</td>\n",
       "      <td>3223.91</td>\n",
       "      <td>495.08</td>\n",
       "      <td>2308.76</td>\n",
       "      <td>617.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12</th>\n",
       "      <td>302.55</td>\n",
       "      <td>122.77</td>\n",
       "      <td>3151.94</td>\n",
       "      <td>484.98</td>\n",
       "      <td>2239.08</td>\n",
       "      <td>589.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-13</th>\n",
       "      <td>305.26</td>\n",
       "      <td>124.97</td>\n",
       "      <td>3161.47</td>\n",
       "      <td>486.66</td>\n",
       "      <td>2261.97</td>\n",
       "      <td>571.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>315.94</td>\n",
       "      <td>127.45</td>\n",
       "      <td>3222.90</td>\n",
       "      <td>493.37</td>\n",
       "      <td>2316.16</td>\n",
       "      <td>589.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-17</th>\n",
       "      <td>315.46</td>\n",
       "      <td>126.27</td>\n",
       "      <td>3270.39</td>\n",
       "      <td>488.94</td>\n",
       "      <td>2321.41</td>\n",
       "      <td>576.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5420 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FB close  AAPL close  AMZN close  NFLX close  GOOG close  \\\n",
       "date                                                                   \n",
       "1999-11-01       NaN       77.62       69.13         NaN         NaN   \n",
       "1999-11-02       NaN       80.25       66.44         NaN         NaN   \n",
       "1999-11-03       NaN       81.50       65.81         NaN         NaN   \n",
       "1999-11-04       NaN       83.62       63.06         NaN         NaN   \n",
       "1999-11-05       NaN       88.31       64.94         NaN         NaN   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "2021-05-11    306.53      125.91     3223.91      495.08     2308.76   \n",
       "2021-05-12    302.55      122.77     3151.94      484.98     2239.08   \n",
       "2021-05-13    305.26      124.97     3161.47      486.66     2261.97   \n",
       "2021-05-14    315.94      127.45     3222.90      493.37     2316.16   \n",
       "2021-05-17    315.46      126.27     3270.39      488.94     2321.41   \n",
       "\n",
       "            TSLA close  \n",
       "date                    \n",
       "1999-11-01         NaN  \n",
       "1999-11-02         NaN  \n",
       "1999-11-03         NaN  \n",
       "1999-11-04         NaN  \n",
       "1999-11-05         NaN  \n",
       "...                ...  \n",
       "2021-05-11      617.20  \n",
       "2021-05-12      589.89  \n",
       "2021-05-13      571.69  \n",
       "2021-05-14      589.74  \n",
       "2021-05-17      576.83  \n",
       "\n",
       "[5420 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check FAANGT_close_df\n",
    "FAANGT_close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data\\\\csv_files\\\\FAANGT_close_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3d453697f6c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.\\Data\\csv_files\\FAANGT_close_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#this will work only when using\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mFAANGT_close_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/csv_files/FAANGT_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFAANGT_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m             )\n\u001b[0;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data\\\\csv_files\\\\FAANGT_close_data.csv'"
     ]
    }
   ],
   "source": [
    "# These directories will work only when called as function in Project Moon Notebook (DO NOT RUN in this notebook if in DATA/ directory or subdirs)\n",
    "FAANGT_close_df.to_csv('Data/csv_files/FAANGT_close_data.csv') \n",
    "FAANGT_df.to_csv('Data/csv_files/FAANGT_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_csv in module pandas.core.generic:\n",
      "\n",
      "to_csv(self, path_or_buf: Union[str, pathlib.Path, IO[~AnyStr], NoneType] = None, sep: str = ',', na_rep: str = '', float_format: Union[str, NoneType] = None, columns: Union[Sequence[Union[Hashable, NoneType]], NoneType] = None, header: Union[bool, List[str]] = True, index: bool = True, index_label: Union[bool, str, Sequence[Union[Hashable, NoneType]], NoneType] = None, mode: str = 'w', encoding: Union[str, NoneType] = None, compression: Union[str, Mapping[str, str], NoneType] = 'infer', quoting: Union[int, NoneType] = None, quotechar: str = '\"', line_terminator: Union[str, NoneType] = None, chunksize: Union[int, NoneType] = None, date_format: Union[str, NoneType] = None, doublequote: bool = True, escapechar: Union[str, NoneType] = None, decimal: Union[str, NoneType] = '.', errors: str = 'strict') -> Union[str, NoneType]\n",
      "    Write object to a comma-separated values (csv) file.\n",
      "    \n",
      "    .. versionchanged:: 0.24.0\n",
      "        The order of arguments for Series was changed.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str or file handle, default None\n",
      "        File path or object, if None is provided the result is returned as\n",
      "        a string.  If a file object is passed it should be opened with\n",
      "        `newline=''`, disabling universal newlines.\n",
      "    \n",
      "        .. versionchanged:: 0.24.0\n",
      "    \n",
      "           Was previously named \"path\" for Series.\n",
      "    \n",
      "    sep : str, default ','\n",
      "        String of length 1. Field delimiter for the output file.\n",
      "    na_rep : str, default ''\n",
      "        Missing data representation.\n",
      "    float_format : str, default None\n",
      "        Format string for floating point numbers.\n",
      "    columns : sequence, optional\n",
      "        Columns to write.\n",
      "    header : bool or list of str, default True\n",
      "        Write out the column names. If a list of strings is given it is\n",
      "        assumed to be aliases for the column names.\n",
      "    \n",
      "        .. versionchanged:: 0.24.0\n",
      "    \n",
      "           Previously defaulted to False for Series.\n",
      "    \n",
      "    index : bool, default True\n",
      "        Write row names (index).\n",
      "    index_label : str or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the object uses MultiIndex. If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R.\n",
      "    mode : str\n",
      "        Python write mode, default 'w'.\n",
      "    encoding : str, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'utf-8'.\n",
      "    compression : str or dict, default 'infer'\n",
      "        If str, represents compression mode. If dict, value at 'method' is\n",
      "        the compression mode. Compression mode may be any of the following\n",
      "        possible values: {'infer', 'gzip', 'bz2', 'zip', 'xz', None}. If\n",
      "        compression mode is 'infer' and `path_or_buf` is path-like, then\n",
      "        detect compression mode from the following extensions: '.gz',\n",
      "        '.bz2', '.zip' or '.xz'. (otherwise no compression). If dict given\n",
      "        and mode is one of {'zip', 'gzip', 'bz2'}, or inferred as\n",
      "        one of the above, other entries passed as\n",
      "        additional compression options.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           May now be a dict with key 'method' as compression mode\n",
      "           and other entries as additional compression options if\n",
      "           compression mode is 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.1.0\n",
      "    \n",
      "           Passing compression options as keys in dict is\n",
      "           supported for compression modes 'gzip' and 'bz2'\n",
      "           as well as 'zip'.\n",
      "    \n",
      "    quoting : optional constant from csv module\n",
      "        Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "        then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "        will treat them as non-numeric.\n",
      "    quotechar : str, default '\\\"'\n",
      "        String of length 1. Character used to quote fields.\n",
      "    line_terminator : str, optional\n",
      "        The newline character or character sequence to use in the output\n",
      "        file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "        this method is called ('\\n' for linux, '\\r\\n' for Windows, i.e.).\n",
      "    \n",
      "        .. versionchanged:: 0.24.0\n",
      "    chunksize : int or None\n",
      "        Rows to write at a time.\n",
      "    date_format : str, default None\n",
      "        Format string for datetime objects.\n",
      "    doublequote : bool, default True\n",
      "        Control quoting of `quotechar` inside a field.\n",
      "    escapechar : str, default None\n",
      "        String of length 1. Character used to escape `sep` and `quotechar`\n",
      "        when appropriate.\n",
      "    decimal : str, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data.\n",
      "    errors : str, default 'strict'\n",
      "        Specifies how encoding and decoding errors are to be handled.\n",
      "        See the errors argument for :func:`open` for a full list\n",
      "        of options.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting csv format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_csv : Load a CSV file into a DataFrame.\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "    ...                    'mask': ['red', 'purple'],\n",
      "    ...                    'weapon': ['sai', 'bo staff']})\n",
      "    >>> df.to_csv(index=False)\n",
      "    'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      "    \n",
      "    Create 'out.zip' containing 'out.csv'\n",
      "    \n",
      "    >>> compression_opts = dict(method='zip',\n",
      "    ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      "    >>> df.to_csv('out.zip', index=False,\n",
      "    ...           compression=compression_opts)  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
